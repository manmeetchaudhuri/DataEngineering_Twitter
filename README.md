# Building a Twitter big data pipeline with Kafka, Python and MongoDB
# Sentiment analysis of Tweets

The task is to create a data pipeline that covers the following aspects:
1)	Data ingestion

From Twitter JSON stream:
All Twitter APIs that return Tweets provide that data encoded using JavaScript Object Notation (JSON). JSON is based on key-value pairs, with named attributes and associated values. These attributes, and their state are used to describe objects.

2)	Data storage

Using Kafka as a buffer storage: 
Apache Kafka is a highly scalable, fast and fault-tolerant messaging application used for streaming applications and data processing.

Store data in MongoDB: 
MongoDB is a document database with the scalability and flexibility that one wants with the querying and indexing that one needs.

3)	Data aggregation and visualization

Queries with aggregation
Display of results in tabular format or other visualizations
